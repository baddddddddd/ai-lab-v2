"""
!!! Code generated by Claude Sonnet 4 !!!
"""

import torch
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import umap
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import argparse
import pickle
import os
from typing import Optional, Dict, List, Tuple
import pandas as pd


class EmbeddingVisualizer:
    def __init__(
        self,
        n_neighbors: int = 15,
        min_dist: float = 0.1,
        n_components: int = 2,
        metric: str = "cosine",
        random_state: int = 42,
    ):
        """
        Interactive visualizer for LLM embeddings using UMAP.

        Args:
            n_neighbors: UMAP parameter - number of neighbors to consider
            min_dist: UMAP parameter - minimum distance between points
            n_components: Number of dimensions for UMAP (2 or 3)
            metric: Distance metric for UMAP
            random_state: Random seed for reproducibility
        """
        self.n_neighbors = n_neighbors
        self.min_dist = min_dist
        self.n_components = n_components
        self.metric = metric
        self.random_state = random_state

        self.umap_reducer = None
        self.embeddings = None
        self.reduced_embeddings = None
        self.labels = None
        self.clusters = None

    def load_embeddings(
        self,
        embedding_layer: torch.nn.Embedding,
        vocab: Optional[Dict[int, str]] = None,
        device: str = "cpu",
    ) -> np.ndarray:
        """
        Extract embeddings from a PyTorch embedding layer.

        Args:
            embedding_layer: PyTorch nn.Embedding layer
            vocab: Optional vocabulary mapping {token_id: token_string}
            device: Device to move tensors to

        Returns:
            numpy array of embeddings
        """
        embedding_layer.eval()
        with torch.no_grad():
            # Get all embeddings
            indices = torch.arange(embedding_layer.num_embeddings, device=device)
            embeddings = embedding_layer(indices).cpu().numpy()

        self.embeddings = embeddings

        # Create labels
        if vocab is not None:
            self.labels = [vocab.get(i, f"token_{i}") for i in range(len(embeddings))]
        else:
            self.labels = [f"token_{i}" for i in range(len(embeddings))]

        print(
            f"Loaded {len(embeddings)} embeddings with dimension {embeddings.shape[1]}"
        )
        return embeddings

    def load_embeddings_from_file(
        self, filepath: str, vocab_path: Optional[str] = None
    ) -> np.ndarray:
        """
        Load embeddings from a saved file (pickle, npy, or pt).

        Args:
            filepath: Path to embedding file
            vocab_path: Optional path to vocabulary file

        Returns:
            numpy array of embeddings
        """
        ext = os.path.splitext(filepath)[1].lower()

        if ext == ".npy":
            embeddings = np.load(filepath)
        elif ext == ".pkl" or ext == ".pickle":
            with open(filepath, "rb") as f:
                embeddings = pickle.load(f)
        elif ext == ".pt" or ext == ".pth":
            embeddings = torch.load(filepath, map_location="cpu").numpy()
        else:
            raise ValueError(f"Unsupported file format: {ext}")

        self.embeddings = embeddings

        # Load vocabulary if provided
        if vocab_path is not None:
            with open(vocab_path, "rb") as f:
                vocab = pickle.load(f)
            self.labels = [vocab.get(i, f"token_{i}") for i in range(len(embeddings))]
        else:
            self.labels = [f"token_{i}" for i in range(len(embeddings))]

        print(
            f"Loaded {len(embeddings)} embeddings with dimension {embeddings.shape[1]}"
        )
        return embeddings

    def fit_umap(self, normalize: bool = True) -> np.ndarray:
        """
        Fit UMAP reducer and transform embeddings.

        Args:
            normalize: Whether to normalize embeddings before UMAP

        Returns:
            Reduced embeddings
        """
        if self.embeddings is None:
            raise ValueError("No embeddings loaded. Call load_embeddings first.")

        embeddings = self.embeddings.copy()

        if normalize:
            scaler = StandardScaler()
            embeddings = scaler.fit_transform(embeddings)

        print("Fitting UMAP...")
        self.umap_reducer = umap.UMAP(
            n_neighbors=self.n_neighbors,
            min_dist=self.min_dist,
            n_components=self.n_components,
            metric=self.metric,
            random_state=self.random_state,
            verbose=True,
        )

        self.reduced_embeddings = self.umap_reducer.fit_transform(embeddings)
        print(f"UMAP fitting complete. Shape: {self.reduced_embeddings.shape}")

        return self.reduced_embeddings

    def cluster_embeddings(self, n_clusters: int = 10) -> np.ndarray:
        """
        Perform K-means clustering on reduced embeddings.

        Args:
            n_clusters: Number of clusters

        Returns:
            Cluster labels
        """
        if self.reduced_embeddings is None:
            raise ValueError("No reduced embeddings. Call fit_umap first.")

        kmeans = KMeans(n_clusters=n_clusters, random_state=self.random_state)
        self.clusters = kmeans.fit_predict(self.reduced_embeddings)

        print(f"Clustering complete. Found {n_clusters} clusters.")
        return self.clusters

    def create_interactive_plot(
        self,
        sample_size: Optional[int] = None,
        show_clusters: bool = True,
        n_clusters: int = 10,
        title: str = "LLM Embedding Visualization",
    ) -> go.Figure:
        """
        Create interactive Plotly visualization.

        Args:
            sample_size: Number of points to sample (None for all)
            show_clusters: Whether to show cluster colors
            n_clusters: Number of clusters if clustering
            title: Plot title

        Returns:
            Plotly figure
        """
        if self.reduced_embeddings is None:
            raise ValueError("No reduced embeddings. Call fit_umap first.")

        # Sample data if requested
        if sample_size is not None and sample_size < len(self.reduced_embeddings):
            indices = np.random.choice(
                len(self.reduced_embeddings), sample_size, replace=False
            )
            reduced_emb = self.reduced_embeddings[indices]
            labels = [self.labels[i] for i in indices]
        else:
            reduced_emb = self.reduced_embeddings
            labels = self.labels
            indices = np.arange(len(reduced_emb))

        # Perform clustering if requested
        if show_clusters:
            if self.clusters is None:
                self.cluster_embeddings(n_clusters)
            clusters = (
                self.clusters[indices] if sample_size is not None else self.clusters
            )
        else:
            clusters = None

        # Create DataFrame for easier plotting
        if self.n_components == 2:
            df = pd.DataFrame(
                {
                    "x": reduced_emb[:, 0],
                    "y": reduced_emb[:, 1],
                    "label": labels,
                    "index": indices,
                }
            )

            if show_clusters:
                df["cluster"] = clusters

            # Create 2D plot
            if show_clusters:
                fig = px.scatter(
                    df,
                    x="x",
                    y="y",
                    color="cluster",
                    hover_data=["label", "index"],
                    title=title,
                    color_continuous_scale="Viridis",
                )
            else:
                fig = px.scatter(
                    df, x="x", y="y", hover_data=["label", "index"], title=title
                )

        else:  # 3D plot
            df = pd.DataFrame(
                {
                    "x": reduced_emb[:, 0],
                    "y": reduced_emb[:, 1],
                    "z": reduced_emb[:, 2],
                    "label": labels,
                    "index": indices,
                }
            )

            if show_clusters:
                df["cluster"] = clusters

            # Create 3D plot
            if show_clusters:
                fig = px.scatter_3d(
                    df,
                    x="x",
                    y="y",
                    z="z",
                    color="cluster",
                    hover_data=["label", "index"],
                    title=title,
                    color_continuous_scale="Viridis",
                )
            else:
                fig = px.scatter_3d(
                    df, x="x", y="y", z="z", hover_data=["label", "index"], title=title
                )

        # Update layout
        fig.update_layout(
            width=1000, height=800, showlegend=True if show_clusters else False
        )

        # Update hover template
        fig.update_traces(
            hovertemplate="<b>%{customdata[0]}</b><br>"
            + "Index: %{customdata[1]}<br>"
            + "X: %{x:.3f}<br>"
            + "Y: %{y:.3f}"
            + ("<br>Z: %{z:.3f}" if self.n_components == 3 else "")
            + "<extra></extra>"
        )

        return fig

    def show_plot(self, fig: go.Figure, auto_open: bool = True, port: int = 8050):
        """
        Show interactive plot with multiple fallback methods.

        Args:
            fig: Plotly figure to display
            auto_open: Whether to try opening browser automatically
            port: Port for local server (if needed)
        """
        import webbrowser
        import tempfile
        import os
        from threading import Timer

        if auto_open:
            # Method 1: Try Plotly's default show
            try:
                fig.show()
                print("Plot opened using Plotly's default method.")
                return
            except Exception as e:
                print(f"Default show failed: {e}")

        # Method 2: Save as temp HTML and open manually
        try:
            with tempfile.NamedTemporaryFile(
                mode="w", suffix=".html", delete=False
            ) as f:
                temp_path = f.name
                fig.write_html(temp_path, auto_open=False)

            print(f"Saved temporary HTML file: {temp_path}")

            # Try to open in browser
            if auto_open:
                try:
                    webbrowser.open("file://" + os.path.abspath(temp_path))
                    print("Plot opened in browser.")

                    # Clean up temp file after delay
                    def cleanup():
                        try:
                            os.unlink(temp_path)
                        except:
                            pass

                    Timer(10.0, cleanup).start()

                except Exception as e:
                    print(f"Failed to auto-open browser: {e}")
                    print(f"Please manually open: file://{os.path.abspath(temp_path)}")
            else:
                print(f"Please manually open: file://{os.path.abspath(temp_path)}")

        except Exception as e:
            print(f"Failed to create temp HTML: {e}")

            # Method 3: Try Plotly offline mode
            try:
                import plotly.offline as pyo

                pyo.plot(fig, filename="embedding_plot.html", auto_open=auto_open)
                print("Plot saved as 'embedding_plot.html'")
            except Exception as e2:
                print(f"All methods failed. Error: {e2}")
                print("Try manually saving the figure:")
                print("fig.write_html('my_plot.html')")

    def save_results(self, output_dir: str):
        """
        Save UMAP results and visualizations.

        Args:
            output_dir: Directory to save results
        """
        os.makedirs(output_dir, exist_ok=True)

        # Save reduced embeddings
        np.save(
            os.path.join(output_dir, "reduced_embeddings.npy"), self.reduced_embeddings
        )

        # Save labels
        with open(os.path.join(output_dir, "labels.pkl"), "wb") as f:
            pickle.dump(self.labels, f)

        # Save clusters if available
        if self.clusters is not None:
            np.save(os.path.join(output_dir, "clusters.npy"), self.clusters)

        # Save UMAP model
        with open(os.path.join(output_dir, "umap_model.pkl"), "wb") as f:
            pickle.dump(self.umap_reducer, f)

        print(f"Results saved to {output_dir}")


def main():
    parser = argparse.ArgumentParser(description="Visualize LLM embeddings with UMAP")
    parser.add_argument(
        "--embeddings",
        type=str,
        required=True,
        help="Path to embeddings file (.npy, .pkl, .pt)",
    )
    parser.add_argument(
        "--vocab", type=str, default=None, help="Path to vocabulary file (.pkl)"
    )
    parser.add_argument(
        "--n_neighbors", type=int, default=15, help="UMAP n_neighbors parameter"
    )
    parser.add_argument(
        "--min_dist", type=float, default=0.1, help="UMAP min_dist parameter"
    )
    parser.add_argument(
        "--n_components",
        type=int,
        default=2,
        choices=[2, 3],
        help="Number of UMAP components (2 or 3)",
    )
    parser.add_argument(
        "--metric", type=str, default="cosine", help="Distance metric for UMAP"
    )
    parser.add_argument(
        "--sample_size",
        type=int,
        default=None,
        help="Number of points to sample for visualization",
    )
    parser.add_argument(
        "--n_clusters", type=int, default=10, help="Number of clusters for K-means"
    )
    parser.add_argument(
        "--no_clusters", action="store_true", help="Disable clustering visualization"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="embedding_results",
        help="Output directory for results",
    )
    parser.add_argument(
        "--title", type=str, default="LLM Embedding Visualization", help="Plot title"
    )

    args = parser.parse_args()

    # Create visualizer
    visualizer = EmbeddingVisualizer(
        n_neighbors=args.n_neighbors,
        min_dist=args.min_dist,
        n_components=args.n_components,
        metric=args.metric,
    )

    # Load embeddings
    visualizer.load_embeddings_from_file(args.embeddings, args.vocab)

    # Fit UMAP
    visualizer.fit_umap(normalize=True)

    # Create interactive plot
    fig = visualizer.create_interactive_plot(
        sample_size=args.sample_size,
        show_clusters=not args.no_clusters,
        n_clusters=args.n_clusters,
        title=args.title,
    )

    # Show plot with better browser opening
    visualizer.show_plot(fig, auto_open=True)

    # Save results
    visualizer.save_results(args.output_dir)

    # Save HTML plot
    fig.write_html(os.path.join(args.output_dir, "embedding_visualization.html"))
    print(
        f"Interactive plot saved to {os.path.join(args.output_dir, 'embedding_visualization.html')}"
    )


if __name__ == "__main__":
    # Example usage for direct import
    print("Example usage:")
    print(
        """
    # Direct usage with PyTorch model:
    import torch.nn as nn
    
    # Create example embedding layer
    embedding_layer = nn.Embedding(1000, 128)
    vocab = {i: f'token_{i}' for i in range(1000)}  # Example vocab
    
    # Create visualizer
    visualizer = EmbeddingVisualizer(n_components=2)
    
    # Load and visualize
    visualizer.load_embeddings(embedding_layer, vocab)
    visualizer.fit_umap()
    fig = visualizer.create_interactive_plot()
    visualizer.show_plot(fig)
    """
    )

    # Run CLI if script is executed directly
    main()
